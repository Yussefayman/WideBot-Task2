{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable2</th>\n",
       "      <th>variable3</th>\n",
       "      <th>variable8</th>\n",
       "      <th>variable11</th>\n",
       "      <th>variable14</th>\n",
       "      <th>variable15</th>\n",
       "      <th>variable17</th>\n",
       "      <th>variable19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3661.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>3.600000e+03</td>\n",
       "      <td>3700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2698.231631</td>\n",
       "      <td>1210.569655</td>\n",
       "      <td>720.540000</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>162.695000</td>\n",
       "      <td>2246.705946</td>\n",
       "      <td>1.626950e+06</td>\n",
       "      <td>0.925405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1690.388911</td>\n",
       "      <td>3163.834623</td>\n",
       "      <td>1930.736215</td>\n",
       "      <td>6.750553</td>\n",
       "      <td>156.045682</td>\n",
       "      <td>8708.571126</td>\n",
       "      <td>1.560457e+06</td>\n",
       "      <td>0.262772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1917.000000</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2558.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3667.000000</td>\n",
       "      <td>452.250000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>1059.750000</td>\n",
       "      <td>2.800000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8025.000000</td>\n",
       "      <td>26335.000000</td>\n",
       "      <td>14415.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1160.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.160000e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable2     variable3     variable8   variable11   variable14  \\\n",
       "count  3661.000000   3700.000000   3700.000000  3700.000000  3600.000000   \n",
       "mean   2698.231631   1210.569655    720.540000     4.160000   162.695000   \n",
       "std    1690.388911   3163.834623   1930.736215     6.750553   156.045682   \n",
       "min      16.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "25%    1917.000000      0.000830      8.000000     0.000000     0.000000   \n",
       "50%    2558.000000     55.000000     71.000000     2.000000   120.000000   \n",
       "75%    3667.000000    452.250000    415.000000     6.000000   280.000000   \n",
       "max    8025.000000  26335.000000  14415.000000    67.000000  1160.000000   \n",
       "\n",
       "          variable15    variable17   variable19  \n",
       "count    3700.000000  3.600000e+03  3700.000000  \n",
       "mean     2246.705946  1.626950e+06     0.925405  \n",
       "std      8708.571126  1.560457e+06     0.262772  \n",
       "min         0.000000  0.000000e+00     0.000000  \n",
       "25%         0.000000  0.000000e+00     1.000000  \n",
       "50%       113.000000  1.200000e+06     1.000000  \n",
       "75%      1059.750000  2.800000e+06     1.000000  \n",
       "max    100000.000000  1.160000e+07     1.000000  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.read_csv(\"C:\\\\Users\\\\Yousef\\\\Desktop\\\\Internship-Task\\\\training.csv\")\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\Yousef\\\\Desktop\\\\Internship-Task\\\\validation.csv\")\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Target value imbalance \n",
    "- Majority class represents 93% , minority class represents 7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data target value distrbution\n",
      "\n",
      "1    3424\n",
      "0     276\n",
      "Name: classLabel, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check target value imbalance\n",
    "train_data ['classLabel']=[1 if i == \"yes.\" else 0 for i in train_data.classLabel]\n",
    "print(\"Training data target value distrbution\\n\")\n",
    "print(train_data['classLabel'].value_counts())\n",
    "test_data['classLabel']=[1 if i == \"yes.\" else 0 for i in test_data.classLabel]\n",
    "# yes. represent 93% , no. represent only 7% percent of the data, there is a class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data using pandas_profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e673244dcc384754bfe22fe8787342d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=33.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2719217348594118b2c5a1168efdd084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yousef\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas_profiling\\visualisation\\plot.py:154: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"RdBu\"))\n",
      "  cmap.set_bad(cmap_bad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b4a191d76f4891b848c45cd03a0dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render HTML', max=1.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e900882a69477991ae2523f334349d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Export report to file', max=1.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Exploring Data using pandas_profiling to get insights about the data.\n",
    "\n",
    "wide_bot_profile = ProfileReport(train_data, title='WideBot Profiling Report', explorative = True)\n",
    "wide_bot_profile\n",
    "wide_bot_profile.to_file(\"WideBot.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIGH CORRELATION\n",
    "- There are highly correlated columns , which could affect the model performance because it's not adding new features or value to the model performance, So i dropped highly correlated columns for training and validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vars:17,19,4,18 have high correlation which could affect the model.\n",
    "train_data =train_data.drop(['variable17','variable19','variable4','variable18'],axis=1)\n",
    "test_data =test_data.drop(['variable17','variable19','variable4','variable18'],axis=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISSING VALUES\n",
    "- Replacing missing categorical values by the most frequent value representing that class , replacing missing numerical values by the median representing that class. I didn't use the mean of the column because the mean could be affected by outliers values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(data):\n",
    "    data['variable1'].fillna('b',inplace=True)\n",
    "    var2_median = data['variable2'].median()\n",
    "    data['variable2'].fillna(var2_median,inplace=True)\n",
    "    data['variable5'].fillna('g',inplace=True)\n",
    "    data['variable6'].fillna('c',inplace=True)\n",
    "    data['variable7'].fillna('v',inplace=True)\n",
    "    var14_median = data['variable14'].median()\n",
    "    data['variable14'].fillna(var14_median,inplace=True)\n",
    "fill_missing_values(train_data)\n",
    "fill_missing_values(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING CATEGORICAL VALUES TO NUMERICAL VALUES.\n",
    "- I used simple label encoder because it's faster approch and works well with tree based models and doesn't consume as much memory as onehot encoder with many distinct values , i didn't use onehot encoder because variable6 has 14 distinct values which could be bad for memory usage, otherwise the onehot encoder could work better than the simple encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace categorical ==> numerical\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "categorical_vars = ['variable1','variable5','variable6','variable7','variable9','variable10','variable12','variable13']\n",
    "cat_cols = train_data[categorical_vars].copy()\n",
    "cat_test_cols=test_data[categorical_vars].copy()\n",
    "\n",
    "for col in cat_cols:\n",
    "    cat_cols[col]=label_encoder.fit_transform(cat_cols[col])\n",
    "    cat_test_cols[col]=label_encoder.transform(cat_test_cols[col])\n",
    "for i in categorical_vars:\n",
    "    train_data[i] = cat_cols[i].values\n",
    "    test_data[i]=cat_test_cols[i].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALIZATION\n",
    "- I used simple type of normalization for numerical values by dividing by the mean of the column, for better performance i could have used min max scaler from sklearn. but i wanted to keep it clean and simple as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable1</th>\n",
       "      <th>variable2</th>\n",
       "      <th>variable3</th>\n",
       "      <th>variable5</th>\n",
       "      <th>variable6</th>\n",
       "      <th>variable7</th>\n",
       "      <th>variable8</th>\n",
       "      <th>variable9</th>\n",
       "      <th>variable10</th>\n",
       "      <th>variable11</th>\n",
       "      <th>variable12</th>\n",
       "      <th>variable13</th>\n",
       "      <th>variable14</th>\n",
       "      <th>variable15</th>\n",
       "      <th>classLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.664503</td>\n",
       "      <td>4.460710e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.495230</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.627421</td>\n",
       "      <td>2.767292e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.238075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.158801</td>\n",
       "      <td>9.293146e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.594276</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.786222</td>\n",
       "      <td>1.102787e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.464929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.198849</td>\n",
       "      <td>2.891201e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.436167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>0</td>\n",
       "      <td>0.695280</td>\n",
       "      <td>6.195430e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.376107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.201923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742845</td>\n",
       "      <td>11.895638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087142</td>\n",
       "      <td>7.434516e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.117967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.201923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>1</td>\n",
       "      <td>1.267079</td>\n",
       "      <td>7.574946e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.062453</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.884615</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>1</td>\n",
       "      <td>1.031982</td>\n",
       "      <td>1.272128e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.520443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.201923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619038</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>0</td>\n",
       "      <td>1.362750</td>\n",
       "      <td>4.233544e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.780384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3700 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variable1  variable2     variable3  variable5  variable6  variable7  \\\n",
       "0             0   0.664503  4.460710e-07          0          2          7   \n",
       "1             1   0.627421  2.767292e-06          2          9          7   \n",
       "2             1   1.158801  9.293146e-01          0          6          2   \n",
       "3             0   1.786222  1.102787e+00          0          7          6   \n",
       "4             1   1.198849  2.891201e-02          0          9          7   \n",
       "...         ...        ...           ...        ...        ...        ...   \n",
       "3695          0   0.695280  6.195430e-02          0         11          7   \n",
       "3696          0   0.087142  7.434516e-07          0         11          7   \n",
       "3697          1   1.267079  7.574946e-01          0          2          7   \n",
       "3698          1   1.031982  1.272128e-01          0          0          7   \n",
       "3699          0   1.362750  4.233544e+00          0          5          7   \n",
       "\n",
       "      variable8  variable9  variable10  variable11  variable12  variable13  \\\n",
       "0      0.242873          0           1    0.240385           1           0   \n",
       "1      0.040248          0           0    0.000000           0           2   \n",
       "2      0.000000          0           1    0.240385           0           0   \n",
       "3      0.464929          0           0    0.000000           0           0   \n",
       "4      0.006939          0           0    0.000000           1           0   \n",
       "...         ...        ...         ...         ...         ...         ...   \n",
       "3695   0.376107          1           1    1.201923           0           0   \n",
       "3696   0.117967          1           1    1.201923           1           0   \n",
       "3697   0.062453          1           1    2.884615           1           0   \n",
       "3698   0.520443          1           1    1.201923           1           0   \n",
       "3699   0.006939          1           0    0.000000           1           0   \n",
       "\n",
       "      variable14  variable15  classLabel  \n",
       "0       0.495230    0.002225           0  \n",
       "1       1.238075    0.000000           0  \n",
       "2       0.594276    0.008457           0  \n",
       "3       0.000000    0.053412           0  \n",
       "4       1.436167    0.000000           0  \n",
       "...          ...         ...         ...  \n",
       "3695    0.742845   11.895638           1  \n",
       "3696    0.742845    0.000000           1  \n",
       "3697    0.000000    0.098366           1  \n",
       "3698    0.619038    0.001335           1  \n",
       "3699    0.000000    1.780384           1  \n",
       "\n",
       "[3700 rows x 15 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize numerical data\n",
    "numerical_vars = ['variable2','variable3','variable8','variable11','variable14','variable15']\n",
    "for i in numerical_vars:\n",
    "    train_data[i]=train_data[i]/np.mean(train_data[i])\n",
    "    test_data[i]=test_data[i]/np.mean(test_data[i])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data imbalance Solution\n",
    "- I used oversampling to make use of every information I have in the data and not to lose any, i would lose more than 3000 data points in undersampling technique. Synthetic samples generation (SMOTE) is a good technique as well to solve data imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2742\n",
       "0    2742\n",
       "Name: classLabel, dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate input features and target\n",
    "y = train_data.classLabel\n",
    "X = train_data.drop('classLabel', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "no_choice = X[X.classLabel==0]\n",
    "yes_choice = X[X.classLabel==1]\n",
    "\n",
    "# upsample minority\n",
    "no_choice_upsample = resample(no_choice,replace=True, n_samples=len(yes_choice),random_state=0) \n",
    "\n",
    "# combine majority and upsampled minority\n",
    "full_data = pd.concat([yes_choice, no_choice_upsample])\n",
    "\n",
    "# check new class counts\n",
    "full_data.classLabel.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING THE MODEL.\n",
    "- I have set 4 metrics to measure model performance, accuracy,f1_score and precision. -\n",
    "- Accuracy: num of right predictions by the model/size of data given. which is not enough.\n",
    "- Precision: num of True positive predictions/num of True positive predicitons+ num of false predicitions.\n",
    "- Recall: num of True positive predicitions/num of True positive predicitions + False negative predicitons.\n",
    "- F1 Score: it considers both recall and precision.\n",
    "- RandomForestClassifier outperform logistic regression and XGBoost on training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY = 0.9905405405405405\n",
      "PRECISION = 0.9898403483309144\n",
      "F1 SCORE = 0.9948942377826404\n",
      "RECALL = 1.0\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST CLASSIFIER\n",
    "y_train = full_data.classLabel\n",
    "X_train = full_data.drop('classLabel', axis=1)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 70).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"ACCURACY = \"+str(accuracy_score(y_test, pred)))\n",
    "print(\"PRECISION = \"+str(precision_score(y_test, pred)))\n",
    "print(\"F1 SCORE = \"+str(f1_score(y_test, pred)))\n",
    "print(\"RECALL = \"+str(recall_score(y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY = 0.9851351351351352\n",
      "Precision = 0.9841269841269841\n",
      "F1 SCORE = 0.9919999999999999\n",
      "RECALL = 1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model2 = XGBClassifier(n_estimators=70,learning_rate=0.05)\n",
    "model2.fit(X_train, y_train, early_stopping_rounds=50, eval_set=[(X_test, y_test)], verbose=False)\n",
    "pred2 = model2.predict(X_test)\n",
    "\n",
    "print(\"ACCURACY = \"+str(accuracy_score(y_test, pred2)))    \n",
    "print(\"Precision = \"+str(precision_score(y_test, pred2))) \n",
    "print(\"F1 SCORE = \"+str(f1_score(y_test, pred2)))\n",
    "print(\"RECALL = \"+str(recall_score(y_test, pred2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICITION ON TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = test_data.classLabel\n",
    "test_data.drop('classLabel',axis=1,inplace=True)\n",
    "test_pred = model.predict(test_data)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.865\n",
      "F1 SCORE = 0.8669950738916257\n",
      "PRECISION = 0.8\n",
      "RECALL = 0.946236559139785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y,test_pred)\n",
    "\n",
    "print(\"Accuracy = \"+str(accuracy_score(y, test_pred)))\n",
    "print(\"F1 SCORE = \"+str(f1_score(y, test_pred)))\n",
    "print(\"PRECISION = \"+str(precision_score(y,test_pred)))\n",
    "print(\"RECALL = \"+str(recall_score(y,test_pred)))\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=labels,fmt=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model accuracy is 86.5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
